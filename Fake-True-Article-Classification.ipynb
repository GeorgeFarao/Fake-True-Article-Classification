{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IgXy6LLiduFJ",
        "03C7E4Agffci",
        "oDC77MUDfxn1",
        "cm6vRCXUgViR",
        "IIWUsPD_haLk",
        "ri5V2iuNhhyl",
        "Q7FS86wa5Lai",
        "-xxRA31wcnRw",
        "HxP2S5WxhI_X",
        "c3M5zemAg99I",
        "bdLHJKdTGnhZ",
        "N9ZceIJ05MTZ",
        "Wr78ic9pWrx2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoT5CWUkRQy2"
      },
      "source": [
        "---\n",
        "## &nbsp;&nbsp;2η Άσκηση  -  Τεχνικές Εξόρυξης Δεδομένων - Εαρινό Εξάμηνο 2020-2021\n",
        "\n",
        "* Φαραώ Γεώργιος&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- &nbsp;&nbsp;sdi1700177\n",
        "* Ροβιθάκης Ιωάννης &nbsp; -&nbsp;&nbsp; sdi1800164\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je6ojADpRxwc"
      },
      "source": [
        "# Σημειώσεις - Παραδοχές"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yiTHeDAR1hj"
      },
      "source": [
        "- 1) Παρατηρήσαμε ότι στις περισσότερες περιπτώσεις, το f1 score αποτέλεσμα της συνάρτησης f1_score(), έβγαινε πάντα το ίδιο με το accuracy της accuracy_score(). Ετσι, δοκιμάσαμε να υπολογίσουμε το f1 score με βάση τον αναλυτικό τύπο του ορισμού του (Τύπος από την wikipedia), γεγονός που μας έδωσε πιο λογικά αποτελέσματα οπότε και το κρατήσαμε έτσι\n",
        "\n",
        "- 2) Επειδή θέλαμε να έχουμε μεγαλύτερη ευελιξία στις δοκιμές μας με τους διάφορους classifiers, αποφασίσαμε να μην χρησιμοποιήσουμε τα train και test datasets που δημιουργούμε στο ερώτημα 3 του πρώτου μέρους. Αντί αυτού, δημιουργούμε ένα πίνακα με τα δεδομένα μας \"έτοιμα\" σε διάφορα στάδια προεπεξεργασίας (πχ με stopwords, χωρις stopwords, με lemmatization κλπ) και στη συνέχεια παίρνουμε τα train και test datasets από αυτόν. Στόχος μας είναι να μπορούμε εύκολα και γρήγορα να βλέπουμε πειραματικά την επιρροή του κάθε σταδίου προεπεξεργασίας στα τελικά μας αποτελέσματα. \n",
        "\n",
        "- 3) Θεωρούμε ότι έχουμε καλύψει επαρκώς τον κώδικα μας σε σχόλια και εξηγήσεις. Για οποιαδήποτε περεταίρω απορία, διευκρίνηση ή παρατήρηση πάνω στην εργασία μας, μην διστάσετε να μας στείλετε ενα email στο sdi1800164@di.uoa.gr ή στο sdi1700177@di.uoa.gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwSmrFwPK_lS"
      },
      "source": [
        "# Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIcpWnbeteHL",
        "outputId": "118ab90e-0be1-4e1c-9704-6d93c591fe38"
      },
      "source": [
        "# Mount the google drive to have access to the files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Import some of the libraries we will need\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import nltk\n",
        "import heapq\n",
        "import pickle\n",
        "import os.path\n",
        "import datetime\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from nltk.stem import *\n",
        "from sklearn import svm\n",
        "from numpy import random\n",
        "from scipy import sparse\n",
        "from sklearn.svm import NuSVC\n",
        "from string import punctuation\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.sparse import csr_matrix\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.patches as mpatches\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from scipy.spatial.distance import hamming\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from gensim.parsing.porter import PorterStemmer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "%matplotlib inline "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "A2GTZhhmO8AZ",
        "outputId": "b52f0e87-8e0d-40b3-d04a-4587e167e360"
      },
      "source": [
        "# Read the input files and create dataframes\n",
        "\n",
        "# Location1 = r'/content/gdrive/MyDrive/TEDE/True.csv'\n",
        "# Location2 = r'/content/gdrive/MyDrive/TEDE/Fake.csv'\n",
        "Location1 = r'/content/gdrive/MyDrive/DataMining2021/TEDE_SHARED/True.csv'\n",
        "Location2 = r'/content/gdrive/MyDrive/DataMining2021/TEDE_SHARED/Fake.csv'\n",
        "\n",
        "true_df = pd.read_csv(Location1)\n",
        "fake_df = pd.read_csv(Location2)\n",
        "fake_df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ...               date\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...  ...  December 31, 2017\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drTrv8Q28d6G"
      },
      "source": [
        "Ξεκινάμε ελέγχοντας αν υπάρχουν κενά στα δεδομένα μας:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWN8iVJT8aNr",
        "outputId": "6375928d-0450-4067-db68-42d8d2d97462"
      },
      "source": [
        "data = [true_df, fake_df]\n",
        "for df in data:\n",
        "  print(df['title'].isnull().unique())\n",
        "  print(df['text'].isnull().unique())\n",
        "  print(df['subject'].isnull().unique())\n",
        "  print(df['date'].isnull().unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False]\n",
            "[False]\n",
            "[False]\n",
            "[False]\n",
            "[False]\n",
            "[False]\n",
            "[False]\n",
            "[False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQd9UuZdMJV"
      },
      "source": [
        "Δεν φαίνεται να υπάρχουν κενές τιμές στα δεδομένα μας οπότε συνεχίζουμε κανονικά"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmxGSrh_ZmI9"
      },
      "source": [
        "Στις προβλέψεις μας, λαμβάνουμε υπόψιν μας μόνο τον τίτλο και το κείμενο. Αποφασίσαμε να το κανουμε έτσι διοτι με τις μεθόδους που χρησιμοποιούμε στα δεδομένα μας, θεωρούμε ότι οι πληροφορίες των στηλών 'subject' και 'date' δεν προσφέρουν κάποια χρήσιμη πληροφορία. Πχ ισως έχει σημασια η ημερομηνια σε σχέση με άλλα δεδομενα (πχ χρονολογικά cross checks για καλύτερη αξιοπιστία), αλλά για τις πολύ \"απλές\" μεθόδους με τις οποίες δουλεύουμε, και από τον τρόπο που λειτουργούν, αποφασίσαμε να τα παραλείψουμε σε αυτό το στάδιο"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CipuFRWQapgc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a074f80a-0861-4faa-a9c0-9c4658a49995"
      },
      "source": [
        "# The stopword \"database\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Returns a list containing the amounts of chars in the given column of the df\n",
        "def getColumnLen(df, col):\n",
        "  lenlist = []\n",
        "  for index, row in df.iterrows():\n",
        "    lenlist.append( len( str(row[col]) ) )\n",
        "  return lenlist\n",
        "\n",
        "# Returns the quotient of title and text lengths as a metric (explanation on part 3 of the assignment)\n",
        "def getColMetrics(df):\n",
        "  titlecounts = getColumnLen(df, 'title')\n",
        "  textcounts  = getColumnLen(df, 'text')\n",
        "\n",
        "  metric = []\n",
        "  for i in range(len(titlecounts)):\n",
        "    metric.append( (textcounts[i]/titlecounts[i])/(textcounts[i]+titlecounts[i]) )\n",
        "  return (titlecounts, textcounts, metric)\n",
        "\n",
        "# Returns the amount of special chars in the given string\n",
        "def countSpec(txt):\n",
        "  puncts = set(punctuation)\n",
        "  count=0\n",
        "  for ch in txt:\n",
        "    if ch in puncts:\n",
        "      count+=1\n",
        "  return count\n",
        "\n",
        "# Get a list containing the amount of special chars in both the title and the content of the articles\n",
        "def getSpecial(df):\n",
        "  speciaList = []\n",
        "  for index, row in df.iterrows():\n",
        "    txt = str(row['title']) + ' ' + str(row['text'])\n",
        "    speciaList.append( countSpec(txt) )\n",
        "  return speciaList\n",
        "\n",
        "# Returns a list that contains all the words of each dataframe record in a srting\n",
        "def getRecStrList(df):\n",
        "  trainList = []\n",
        "  for index, row in df.iterrows():\n",
        "    txt = str(row['title']) + ' ' + str(row['text'])\n",
        "    trainList.append(txt)\n",
        "  return trainList\n",
        "\n",
        "# Removes the stopwords from a string\n",
        "def remove_stopwords(text):\n",
        "  words = nltk.sent_tokenize(text)\n",
        "  if len(words)==0:\n",
        "    return ''\n",
        "  temp_list= words[0].split()\n",
        "  filtered = [w for w in temp_list if not w in stop_words]\n",
        "  words[0]=\" \".join(filtered)\n",
        "  return words[0]\n",
        "\n",
        "# Return the given text lemmatized (word by word)\n",
        "def lemmatize(text):\n",
        "  ps = PorterStemmer()\n",
        "  tmp_list = text.split()\n",
        "  for i, word in enumerate(tmp_list):\n",
        "    tmp_list[i] = ps.stem(word)\n",
        "  return ' '.join(tmp_list)\n",
        "\n",
        "# Return the given text without single letter words\n",
        "def remove_single_letters(text):\n",
        "  words = nltk.word_tokenize(text)\n",
        "  result = [x for x in words if len(x)>2]\n",
        "  result = \" \".join(result)\n",
        "  return result\n",
        "\n",
        "# Based on the true and fake dataframes, get a dataframe the data in a lot of different processed formats\n",
        "# to use for better testing down the line\n",
        "def getInitialFormat(true_df, fake_df):\n",
        "  # Create copies of the initial dataframes to not affect them\n",
        "  tmp_true = true_df.copy()\n",
        "  tmp_fake = fake_df.copy()\n",
        "  # tmp_true = true_df.head(2400).copy()\n",
        "  # tmp_fake = fake_df.head(2400).copy()\n",
        "\n",
        "  # Add the label column and merge the two dataframes\n",
        "  tmp_fake.insert(0,'label','0')\n",
        "  tmp_true.insert(0,'label','1')\n",
        "  tmp_df = pd.concat([tmp_true,tmp_fake], ignore_index=True)\n",
        "\n",
        "  # Create the new dataframe and add the processed level columns\n",
        "  format_df = pd.DataFrame()\n",
        "  format_df['Label'] = tmp_df['label']\n",
        "  format_df['RAW']   = getRecStrList(tmp_df)\n",
        "  format_df['Symbol'] = format_df['RAW'].str.lower().replace(r'\\s+', ' ', regex=True)\n",
        "  format_df['Preprocess'] = format_df['Symbol'].str.replace(r'[^a-zA-Z0-9]', ' ', regex=True)\n",
        "  format_df['StopWords'] = format_df['Preprocess'].apply( remove_stopwords )\n",
        "  format_df['Lemmatized'] = format_df['StopWords'].apply( lemmatize )\n",
        "\n",
        "  format_df['titleLens'], format_df['textLens'], format_df['lenMetric'] = getColMetrics(tmp_df)\n",
        "  format_df['specialCharMetric'] = getSpecial(tmp_df)\n",
        "  return format_df\n",
        "\n",
        "# (Mostly Used in the 2nd and 3rd part of the assignment for tests)\n",
        "format_df = getInitialFormat(true_df, fake_df)\n",
        "display(format_df.tail(5))\n",
        "display(format_df.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4584daa3a25f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# (Mostly Used in the 2nd and 3rd part of the assignment for tests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mformat_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetInitialFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4584daa3a25f>\u001b[0m in \u001b[0;36mgetInitialFormat\u001b[0;34m(true_df, fake_df)\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RAW'\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mgetRecStrList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m   \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Symbol'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RAW'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m   \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Preprocess'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^a-zA-Z0-9]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StopWords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Preprocess'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mremove_stopwords\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6587\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NA -> 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6588\u001b[0m                     new_data = self._mgr.replace(\n\u001b[0;32m-> 6589\u001b[0;31m                         \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6590\u001b[0m                     )\n\u001b[1;32m   6591\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, value, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"BlockManager\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     def replace_list(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, regex, convert)\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m         return self._replace_single(\n\u001b[0;32m-> 2500\u001b[0;31m             \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2501\u001b[0m         )\n\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_replace_single\u001b[0;34m(self, to_replace, value, inplace, regex, convert, mask)\u001b[0m\n\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2588\u001b[0;31m             \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m             \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2106\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                       for a in args]\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mre_replacer\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m   2579\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mre_replacer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mrx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzAxsWivh-Am"
      },
      "source": [
        "---\n",
        "# **Μέρος 1ο**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgXy6LLiduFJ"
      },
      "source": [
        "# **Ερώτημα 1:**\n",
        "**Προεπεξεργασία/καθάρισμα**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MEN19st9rXi"
      },
      "source": [
        "Θα περάσουμε τα δεδομένα μας από μια σειρά απο βήματα προεπεξεργασίας με στόχο την βελτιωση της απόδοσης στα επόμενα στάδια."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlkQpkMcbzAO"
      },
      "source": [
        "Στο στάδιο αυτό, απλά κάνουμε decapitalize τους χαρακτήρες και αφαιρούμε τους ανεπιθύμητους χαρακτήρες"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03vj7tdLydj"
      },
      "source": [
        "# A function that processes the given string and removes unwanted characters\n",
        "def preprocess(text):\n",
        "  words = nltk.sent_tokenize(text)\n",
        "  for i in range(len(words)):\n",
        "    words[i] = words[i].lower()\n",
        "    words[i] = re.sub(\"[^a-zA-Z0-9]\", \" \", str(words[i]))\n",
        "    words[i] = re.sub(r'\\W', ' ', words[i])\n",
        "    words[i] = re.sub(r'\\s+', ' ', words[i])\n",
        "\n",
        "  if len(words)==0:\n",
        "    return ''\n",
        "  return words[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tP4ofzVJ9OU"
      },
      "source": [
        "# Remove all the unwanted characters and decapitalize the text for all dataframes\n",
        "for df in data:\n",
        "  for index, row in df.iterrows():\n",
        "    row['title'] = preprocess( row['title'] )\n",
        "    row['text'] = preprocess( row['text'] )\n",
        "  \n",
        "# In general, we got good enough results without any symbols so we decided to remove them all\n",
        "# Indeed keeping some symbols may prove useful in a lot of cases (Like the given lab example: \n",
        "# Fake articles may contain a lot more exclamation marks '!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8ktEc9seuGS"
      },
      "source": [
        "Δεν αφαιρούμε ακόμα τα stopwords καθώς αυτό αποτελεί κομμάτι επόμενου ερωτήματος"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz-JPMGpz5ce"
      },
      "source": [
        "# **Ερώτημα 2:**\n",
        "**Μελέτη των δεδομένων**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03C7E4Agffci"
      },
      "source": [
        "# 2.α:\n",
        "Οπτικοποίηση των πιο δημοφιλών όρων στους τίτλους των άρθρων"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llRkqcu0Q-aM"
      },
      "source": [
        "# Returns a string that contains all the text from the given column\n",
        "def getColAsString(df, column):\n",
        "  text = ''\n",
        "  for index, row in df.iterrows():\n",
        "    text += row[column]\n",
        "  return text\n",
        "\n",
        "# Given text, it prints its wordcloud plot (WordCloud handles the word ranking for us)\n",
        "def printWordCloud(text):\n",
        "  stopwords = set(STOPWORDS) # Ignore the stopwords in the wordcloud\n",
        "  wordcloud = WordCloud(stopwords=stopwords).generate(text)\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "# Print a word cloud for each article category\n",
        "print(\" Most popular words in Real articles\")\n",
        "text = getColAsString(true_df, 'title')\n",
        "printWordCloud(text)\n",
        "\n",
        "print(\"\\n Most popular words in Fake articles\")\n",
        "text = getColAsString(fake_df, 'title')\n",
        "printWordCloud(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDC77MUDfxn1"
      },
      "source": [
        "# 2.β:\n",
        "Οπτικοποίηση του μέσου όρου χαρακτήρων στα αληθινά ενάντια στα ψεύτικα άρθρα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_SZOPMYJRXE"
      },
      "source": [
        "# Returns the average amount of characters in the given column of the given dataframe\n",
        "def charCount(df, column):\n",
        "  totalchars = 0\n",
        "  for index, row in df.iterrows():\n",
        "    totalchars += len(row[column])\n",
        "  return totalchars/len(df)\n",
        "\n",
        "# Etract the needed information\n",
        "t_ti = charCount(true_df, 'title')\n",
        "t_te = charCount(true_df, 'text')\n",
        "f_ti = charCount(fake_df, 'title')\n",
        "f_te = charCount(fake_df, 'text')\n",
        "\n",
        "# And plot the results\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.ylim([0, 290])\n",
        "plt.title(' Average amount of characters per (Real vs Fake) Article Title and Text')\n",
        "plt.ylabel(' Average amount of characters')\n",
        "\n",
        "barplt = plt.bar( ['True Titles', 'Fake Titles', 'True Text', 'Fake Text'], [t_ti, f_ti, t_te, f_te] )\n",
        "\n",
        "# Color code the plot\n",
        "barplt[0].set_color('tab:blue')\n",
        "barplt[2].set_color('tab:blue')\n",
        "barplt[1].set_color('tab:orange')\n",
        "barplt[3].set_color('tab:orange')\n",
        "\n",
        "# And add a legend\n",
        "blue_patch = mpatches.Patch(color='tab:blue', label='Real Articles')\n",
        "orange_patch = mpatches.Patch(color='tab:orange', label='Fake Articles')\n",
        "plt.legend(handles=[blue_patch, orange_patch])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA2XgeMACcgr"
      },
      "source": [
        "Όσον αφορά το πλήθος των χαρακτήρων, φαίνεται τα ψεύτικα άρθρα να έχουν μεγαλύτερους κατα μέσο όρο τίτλους και μικρότερο περιεχόμενο συνολικά σχετικά με τα πραγματικά. (Αν και σε μικρό βαθμό)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AXaiElLoinc"
      },
      "source": [
        "Note: It would be interesting to run this without removing the sybols during preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm6vRCXUgViR"
      },
      "source": [
        "# 2.γ:\n",
        "Οπτικοποίηση των κατανομών πλήθους λέξεων σε τίτλους και κειμενο για αληθινά ενάντια σε ψεύτικα άρθρα <br/> (Με Stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0hmA8SdZWgH"
      },
      "source": [
        "# A function that breaks the given dictionary into two lists (keys : data) to allow easier plotting\n",
        "def break_dict(d):\n",
        "  keys = []\n",
        "  data = []\n",
        "  for key in d:\n",
        "    keys.append(key)\n",
        "    data.append(d[key])\n",
        "  return (keys, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zChzLS1eYOWD"
      },
      "source": [
        "# Return a dictionary with all the article 'classes', based on the amount of words in the given column\n",
        "def getWordDistribution(df, column):\n",
        "  classes = dict()\n",
        "  for index, row in df.iterrows():\n",
        "    # Count the words in the given column\n",
        "    wordCount = len(row[column].split())\n",
        "    # And increment the correct class counter\n",
        "    if wordCount not in classes:\n",
        "      classes[wordCount] = 0\n",
        "    else:\n",
        "      classes[wordCount] += 1\n",
        "  return classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGOtgSrzZnHL"
      },
      "source": [
        "# Prepare the legends\n",
        "blue_patch = mpatches.Patch(color='tab:blue', label='Real Articles')\n",
        "orange_patch = mpatches.Patch(color='tab:orange', label='Fake Articles')\n",
        "\n",
        "# Plot the results for Article Titles\n",
        "plt.figure(figsize=(20,10))\n",
        "keys, data = break_dict( getWordDistribution(true_df, 'title') )\n",
        "plt.bar(keys, data)\n",
        "plt.title(' Word Distribution in Article Titles')\n",
        "plt.ylabel(' Amount of Articles')\n",
        "plt.xlabel(' Amount of Words')\n",
        "keys, data = break_dict( getWordDistribution(fake_df, 'title') )\n",
        "plt.bar(keys, data, alpha=0.75)\n",
        "plt.legend(handles=[blue_patch, orange_patch], prop={'size': 25})\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# Plot the results for Article Text\n",
        "plt.figure(figsize=(30,20))\n",
        "keys, data = break_dict( getWordDistribution(true_df, 'text') )\n",
        "plt.bar(keys, data)\n",
        "plt.title(' Word Distribution in Article Text')\n",
        "plt.ylabel(' Amount of Articles')\n",
        "plt.xlabel(' Amount of Words')\n",
        "keys, data = break_dict( getWordDistribution(fake_df, 'text') )\n",
        "plt.bar(keys, data, alpha=0.75)\n",
        "plt.legend(handles=[blue_patch, orange_patch], prop={'size': 35})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkK4zH0ODEhq"
      },
      "source": [
        "Όπως και σε επίπεδο χαρακτήρων παραπάνω, έτσι και σε επίπεδο λέξεων, φαίνεται να ακολουθείται η ίδια τάση από τα ψεύτικα άρθρα: \"Κατα μέσο όρο μεγαλύτεροι τίτλοι με συντομότερο περιεχόμενο\" <br/>\n",
        "\n",
        "Ειδικά από το γράφημα περιεχομένου-λέξεων γίνεται πιο αισθητός ο διαχωρισμός μεταξύ πραγματικών και ψεύτικων άρθρων, με ξεκάθαρο διαχωρισμό μεταξύ των δύο κατανομών. Απο πλευράς λέξεων, η μεγάλη πλειοψηφία των ψευτικων άρθρων έχει σημαντικά λιγότερες λέξεις από το μέσο πραγματικό άρθρο. Ταυτόχρονα, ενώ τα πραγματικά άρθρα ακολουθούν μια αναμενόμενα κανονική κατανομή, τα ψεύτικα, ξεχωρίζουν από την τάση της κατανομής τους προς τις μικρές τιμές και το σημαντικά μεγαλύτερο (σχεδόν διπλάσιο) εύρος τους. Αρκετά Ψευτικά άρθρα εχουν μεγάλο πλήθος λέξεων, πιθανότατα επειδή για κάποιους χρήστες-στοχους το μέγεθος του κειμένου, του προσθέτει και αξιοπιστία."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIWUsPD_haLk"
      },
      "source": [
        "# 2.δ:\n",
        "Οπτικοποίηση των κατανομών πλήθους λέξεων σε τίτλους και κειμενο για αληθινά ενάντια σε ψεύτικα άρθρα <br/> (Χωρίς Stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QlDA1v1uy_h"
      },
      "source": [
        "Αφαιρούμε τα stopwords από τα δεδομένα μας και ξανακάνουμε τις μετρήσεις μας"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrT2hXnzeTEx"
      },
      "source": [
        "data = [true_df, fake_df]\n",
        "\n",
        "# Remove all the stopwords from the dataframe fields\n",
        "for df in data:\n",
        "  for index, row in df.iterrows():\n",
        "    row['title'] = remove_stopwords( row['title'] )\n",
        "    row['text'] = remove_stopwords( row['text'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ItfQIquyEB"
      },
      "source": [
        "# Prepare the legends\n",
        "blue_patch = mpatches.Patch(color='tab:blue', label='Real Articles')\n",
        "orange_patch = mpatches.Patch(color='tab:orange', label='Fake Articles')\n",
        "\n",
        "# Plot the results for Article Titles\n",
        "plt.figure(figsize=(20,10))\n",
        "keys, data = break_dict( getWordDistribution(true_df, 'title') )\n",
        "plt.bar(keys, data)\n",
        "plt.title(' Word Distribution in Article Titles')\n",
        "plt.ylabel(' Amount of Articles')\n",
        "plt.xlabel(' Amount of Words')\n",
        "keys, data = break_dict( getWordDistribution(fake_df, 'title') )\n",
        "plt.bar(keys, data, alpha=0.75)\n",
        "plt.legend(handles=[blue_patch, orange_patch], prop={'size': 25})\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "# Plot the results for Article Text\n",
        "plt.figure(figsize=(30,20))\n",
        "keys, data = break_dict( getWordDistribution(true_df, 'text') )\n",
        "plt.bar(keys, data)\n",
        "plt.title(' Word Distribution in Article Text')\n",
        "plt.ylabel(' Amount of Articles')\n",
        "plt.xlabel(' Amount of Words')\n",
        "keys, data = break_dict( getWordDistribution(fake_df, 'text') )\n",
        "plt.bar(keys, data, alpha=0.75)\n",
        "plt.legend(handles=[blue_patch, orange_patch], prop={'size': 35})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dTtdvrHFiSc"
      },
      "source": [
        "Η αφαίρεση των stopwords δεν επηρέασε σημαντικά τις κατανομές και τις παρατηρήσεις μας. Υποθέτουμε πως η αφαίρεση των stopwords από τα ψεύτικα άρθρα \"αντισταθμίζεται\" σε κάποιο βαθμό από αυτή στα αληθινά με αποτέλεσμα να μην επηρεάζονται σημαντικά τα τελικά αποτελέσματα - κατανομές."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri5V2iuNhhyl"
      },
      "source": [
        "# 2.ε:\n",
        "Ποια είναι τα πιο συχνά bigrams στους τίτλους και ποιά στο κυρίως άρθρο;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCbMtWyZYj1c"
      },
      "source": [
        "# Find frequency of bigrams in our dataframes' titles and texts\n",
        "# We have removed stoprwords in this steps in order to get more informative results\n",
        "\n",
        "def bigramFrequency(df, column, topk):\n",
        "  # Make a CountVectorizer model with max_festures to find only the top k bigrams we want\n",
        "  word_vectorizer = CountVectorizer(ngram_range=(2,2),max_features=topk, analyzer='word')  \n",
        "  # Train it using the desired column from the dataframe\n",
        "  sp_matrix = word_vectorizer.fit_transform(df[column])      \n",
        "  # Store the frequencies as an array            \n",
        "  frequencies = sum(sp_matrix).toarray()[0]\n",
        "  # Convert frequencies to a dataframe in order to present them in a more easy for the eye way\n",
        "  bigr_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['Frequency'])\n",
        "  # Sort values in a descending order\n",
        "  bigr_df = bigr_df.sort_values('Frequency', ascending=False)                                             \n",
        "  display(bigr_df)\n",
        "  print()\n",
        "\n",
        "bigramFrequency(true_df,'title',10)\n",
        "bigramFrequency(true_df,'text',10)\n",
        "bigramFrequency(fake_df,'title',10)\n",
        "bigramFrequency(fake_df,'text',10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7FS86wa5Lai"
      },
      "source": [
        "# **Ερώτημα 3:**\n",
        "**Δημιουργία συνόλου εκμάθησης και δοκιμής**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaGwKPVD5FQl"
      },
      "source": [
        "# Create a dataframe based on equal amounts of true and fake articles\n",
        "# (containing part of the initial dataset for better testing performance)\n",
        "true_df_sliced = true_df.head(2400)\n",
        "true_df_sliced.insert(4,'label','1')\n",
        "fake_df_sliced = fake_df.head(2400)\n",
        "fake_df_sliced.insert(4,'label','0')\n",
        "merged_df = pd.concat([true_df_sliced,fake_df_sliced], ignore_index=True)\n",
        "\n",
        "# Create the train and test dataset themselves\n",
        "train = merged_df.sample(frac=0.8,random_state=250)\n",
        "test = merged_df.drop(train.index)\n",
        "# And store them in files as required\n",
        "train.to_csv(r'/content/gdrive/MyDrive/DataMining2021/TEDE_SHARED/train.csv', index=False)\n",
        "test.to_csv(r'/content/gdrive/MyDrive/DataMining2021/TEDE_SHARED/test.csv', index=False)\n",
        "\n",
        "print(\"Merged length:\",len(merged_df),\", train length:\",len(train),', test length:',len(test), '\\n')\n",
        "# display(train.tail(1))\n",
        "# print('\\n')\n",
        "# display(test.tail(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxRA31wcnRw"
      },
      "source": [
        "---\n",
        "# **Μέρος 2ο**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivvTv62qMDbg"
      },
      "source": [
        "Για μεγαλύτερη ευκολία/ευελιξία, δημιουργήσαμε για το κομμάτι αυτό ενα ξεχωριστό dataframe και κατα συνέπεια διαφορετικά train και test dataframes. Το dataframe αυτό αποτελείται από τα δεδομένα μας σε διαφορετικά 'στιγμιότυπα' επεξεργασίας σε κάθε στήλη, από τα 'ωμα'-αρχικά δεδομένα, σε δεδομένα χωρις stopwords και lemmatized. Φτιάξαμε ετσι τα δεδομένα μας ωστε να έχουμε την ευελιξία με αλλαγή μόλις μιας παραμέτρου να μπορούμε να συγκρίνουμε την απόδοση των δεδομένων μας σε διαφορετικά σταδια επεξεργασίας, χωρις αναμονές καθώς ειναι όλα έτοιμα-προεπεξεργασμένα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxP2S5WxhI_X"
      },
      "source": [
        "# **Representations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwDSzKy4e3gG"
      },
      "source": [
        "# Create the train and test data/labels using the built in function train_test_split()\n",
        "traindata, testdata, trainlabel, testlabel = train_test_split(format_df['Lemmatized'], format_df['Label'],train_size=0.8, random_state=250, stratify=format_df['Label'])\n",
        "\n",
        "# Create all the different data representations that we will be working on:\n",
        "\n",
        "# BoW: Create a bow vectorizer, fit to it the train data and then transform the testing data \n",
        "# using the resulting bow, to end up with two BoWs that have the same amount of characteristics \n",
        "bow = CountVectorizer()\n",
        "traindata_bow = bow.fit_transform(traindata)\n",
        "testdata_bow = bow.transform(testdata)\n",
        "\n",
        "# TF-IDF: Create the tf-idf transformer using the generated BoWs from above\n",
        "tfidf = TfidfTransformer()\n",
        "traindata_tfidf = tfidf.fit_transform(traindata_bow)\n",
        "testdata_tfidf  = tfidf.transform(testdata_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J3voJlwe3gH"
      },
      "source": [
        "# The word2vec vector size = the amount of 'features' of each word\n",
        "feature_amount = 256 \n",
        "\n",
        "# Returns an array containing the document vectors of each article from the given dataset\n",
        "def getDocVec(dataset, model):\n",
        "  # Get the document-feature vectors for each record-article of the train data\n",
        "  data_list = [] # Store all the data vectors in this list\n",
        "\n",
        "  # Get each article in the data\n",
        "  for i, row in dataset.to_frame().iterrows():\n",
        "    # Temporary array to store this row's vectors, initialized in zeros to act as an 'article-global' averaging vector\n",
        "    avg_vec = np.zeros(feature_amount)   \n",
        "    # Get the words of this article\n",
        "    tokens = nltk.word_tokenize(row['Lemmatized'])\n",
        "\n",
        "    # For every word in this article\n",
        "    for token in tokens:\n",
        "      # If it exists on our Word2vec dictionary\n",
        "      if token in model.wv:\n",
        "        # We add this word's vector to the article's total average vector, averaged by its word length\n",
        "        avg_vec += (model.wv[token]/len(tokens))\n",
        "\n",
        "    # Store the resulting document vector\n",
        "    data_list.append(avg_vec)\n",
        "\n",
        "  # Return the resulting list as an array\n",
        "  return np.array(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0e4gkAwe3gI"
      },
      "source": [
        "# Word2Vec:\n",
        "\n",
        "# Break the train data into tokens to pass to word2vec \n",
        "# (We use only train data to train the model)\n",
        "tokens = [nltk.word_tokenize(strings) for strings in traindata.to_frame()['Lemmatized']]\n",
        "\n",
        "# Initialize and train the word2vec model\n",
        "# (We ended up with these parameter values after a bit of trial and error)\n",
        "w2v_model = Word2Vec(min_count=2, size=256, workers=multiprocessing.cpu_count(), window=5 , sg=0)\n",
        "w2v_model.build_vocab(tokens)\n",
        "w2v_model.train(tokens, total_examples=len(tokens), epochs=8)\n",
        "\n",
        "# Get the document vectors for each dataset\n",
        "traindata_w2v = getDocVec(traindata, w2v_model)\n",
        "testdata_w2v  = getDocVec(testdata, w2v_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et6LT0_1e3gI"
      },
      "source": [
        "# Add the min value of each vector array as an offset to the array to make it non-negative\n",
        "# And allow it to work with MultinomialNB() in Naive Bayes\n",
        "# It does not alter the data or change the accuracy, it just 'shifts' it to make it positive\n",
        "trainmin = np.amin(traindata_w2v)\n",
        "testmin = np.amin(testdata_w2v)\n",
        "\n",
        "if trainmin < 0 :\n",
        "  traindata_w2v += abs(trainmin)\n",
        "\n",
        "if testmin < 0 :\n",
        "  testdata_w2v += abs(testmin)\n",
        "\n",
        "# print(np.amin(traindata_w2v))\n",
        "# print(np.amin(testdata_w2v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNnQIhN2e3gJ"
      },
      "source": [
        "# Flag. If set to 1, it enables analytic classification reports ( classification_report() )\n",
        "analStats = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3M5zemAg99I"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1MvhFiJgKIH"
      },
      "source": [
        "# Given the train and test data/labels, it calculates and prints the accuracy and f1 score of a Logistic regression model \n",
        "def LogisticClassification(traindata, trainlabel, testdata, testlabel):\n",
        "  # Create a logistic regression model\n",
        "  model = LogisticRegression(max_iter=1000)\n",
        "  # Fit the train dat to it\n",
        "  model.fit(traindata, trainlabel)\n",
        "  # Make a prediction\n",
        "  prediction = model.predict(testdata)\n",
        "  # Get the true/false positive/negative results using a confusion matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(testlabel, prediction).ravel()\n",
        "\n",
        "  # Get a full acurracy report\n",
        "  if (analStats == 1):\n",
        "    print( classification_report(testlabel.to_frame(),prediction) )\n",
        "\n",
        "  # Calculate and Print the scores (Use true/false positive/negative to calculate the f1 score)\n",
        "  print(' Accuracy: %.2f%%' % (accuracy_score(testlabel, prediction)*100) )\n",
        "  print(' F1 Score: %.2f%%' % ( (tp/(tp+(fp+fn)/2))*100) )\n",
        "\n",
        "  # Finally, plot the comfusion matrix for a better visualization\n",
        "  plot_confusion_matrix(model, testdata, testlabel, display_labels=['Fake', 'Real', 'Fake', 'Real'])  \n",
        "  plt.show()  \n",
        "  print('\\n')\n",
        "  \n",
        "# Run a test for each representation\n",
        "print(\" > Logistic Regression using BoW\")\n",
        "LogisticClassification(traindata_bow, trainlabel, testdata_bow, testlabel)\n",
        "print(\" > Logistic Regression using TF-IDF\")\n",
        "LogisticClassification(traindata_tfidf, trainlabel, testdata_tfidf, testlabel)\n",
        "print(\" > Logistic Regression using Word2Vec\")\n",
        "LogisticClassification(traindata_w2v, trainlabel, testdata_w2v, testlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdLHJKdTGnhZ"
      },
      "source": [
        "# **Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peAli4qOGsez"
      },
      "source": [
        "# Given the train and test data/labels, it calculates and prints the accuracy and f1 score of a Naive Bayes model \n",
        "def naiveBayesClassification(traindata, trainlabel, testdata, testlabel):\n",
        "  # Create a naive Bayes classification model\n",
        "  model = MultinomialNB()\n",
        "\n",
        "  # Fit the train data to it\n",
        "  model.fit(traindata, trainlabel)\n",
        "\n",
        "  # Make a prediction\n",
        "  prediction = model.predict(testdata)\n",
        "  # Get the true/false positive/negative results using a confusion matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(testlabel, prediction).ravel()\n",
        "  # Get a full acurracy report\n",
        "  if (analStats == 1):\n",
        "    print( classification_report(testlabel.to_frame(),prediction) )\n",
        "\n",
        "  # Calculate and Print the scores (Use true/false positive/negative to calculate the f1 score)\n",
        "  print(' Accuracy: %.2f%%' % (accuracy_score(testlabel, prediction)*100) )\n",
        "  print(' F1 Score: %.2f%%' % ( (tp/(tp+(fp+fn)/2))*100) )\n",
        "\n",
        "  # Finally, plot the comfusion matrix for a better visualization\n",
        "  plot_confusion_matrix(model, testdata, testlabel, display_labels=['Fake', 'Real', 'Fake', 'Real'])  \n",
        "  plt.show()  \n",
        "  print('\\n')\n",
        "\n",
        "# Run a test for each representation\n",
        "print(\" > Naive Bayes using BoW\")\n",
        "naiveBayesClassification(traindata_bow, trainlabel, testdata_bow, testlabel)\n",
        "print(\" > Naive Bayes using TF-IDF\")\n",
        "naiveBayesClassification(traindata_tfidf, trainlabel, testdata_tfidf, testlabel)\n",
        "print(\" > Naive Bayes using Word2Vec\")\n",
        "naiveBayesClassification(traindata_w2v, trainlabel, testdata_w2v, testlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ZceIJ05MTZ"
      },
      "source": [
        "# **Support Vector Machines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8nHaUxj5Kg4"
      },
      "source": [
        "# Given the train and test data/labels, it calculates and prints the accuracy and f1 score of a SVM model \n",
        "def svmClassification(traindata, trainlabel, testdata, testlabel, kernel_type):\n",
        "  # Create a SVM classification model\n",
        "  model = svm.LinearSVC(random_state=0, tol=1e-5)\n",
        "  # Fit the train dat to it\n",
        "  model.fit(traindata, trainlabel)\n",
        "  # Make a prediction\n",
        "  prediction = model.predict(testdata)\n",
        "  # Get the true/false positive/negative results using a confusion matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(testlabel, prediction).ravel()\n",
        "\n",
        "  # Get a full acurracy report\n",
        "  if (analStats == 1):\n",
        "    print( classification_report(testlabel.to_frame(),prediction) )\n",
        "\n",
        "  # Calculate and Print the scores (Use true/false positive/negative to calculate the f1 score)\n",
        "  print(' Accuracy: %.2f%%' % (accuracy_score(testlabel, prediction)*100) )\n",
        "  print(' F1 Score: %.2f%%' % ( (tp/(tp+(fp+fn)/2))*100) )\n",
        "\n",
        "  # Finally, plot the comfusion matrix for a better visualization\n",
        "  plot_confusion_matrix(model, testdata, testlabel, display_labels=['Fake', 'Real', 'Fake', 'Real'])  \n",
        "  plt.show()  \n",
        "  print('\\n')\n",
        "\n",
        "# Run a test for each representation\n",
        "print(\" > SVM using BoW with linear kernel\")\n",
        "svmClassification(traindata_bow, trainlabel, testdata_bow, testlabel,'linear')\n",
        "print(\" > SVM using TF-IDF linear kernel\")\n",
        "svmClassification(traindata_tfidf, trainlabel, testdata_tfidf, testlabel,'linear')\n",
        "print(\" > SVM using Word2Vec with linear kernel\")\n",
        "svmClassification(traindata_w2v, trainlabel, testdata_w2v, testlabel,'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh_kQjY64HAD"
      },
      "source": [
        "Κάναμε αρκετές δοκιμές με χρήση ποικιλίας παραμέτρων καθώς και δοκιμές με την χρήση GridSearchCV και καταλήξαμε στα εξής:\n",
        "\n",
        "Σε γενικές γραμμές, με το rdf kernel είχαμε λίγο χειρότερη ακρίβεια και με μεγάλο κόστος σε χρονική πολυπλοκότητα. Θεωρούμε ότι για τις ανάγκες μας στην συγκεκριμένη περίπτωση ο linear svc επιτυγχάνει εξαιρετικά αποτελέσματα σε ελάχιστο χρόνο οπότε και τον προτιμήσαμε."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr78ic9pWrx2"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Hc2ktBS-HU"
      },
      "source": [
        "# Given the train and test data/labels, it calculates and prints the accuracy and f1 score of a Random Forest model \n",
        "def randomForestClassification(traindata, trainlabel, testdata, testlabel):\n",
        "  # Create a RandomForest classification model\n",
        "  model = RandomForestClassifier(random_state=164)\n",
        "  # Fit the train dat to it\n",
        "  model.fit(traindata, trainlabel)\n",
        "  # Make a prediction\n",
        "  prediction = model.predict(testdata)\n",
        "  # Get the true/false positive/negative results using a confusion matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(testlabel, prediction).ravel()\n",
        "\n",
        "  # Get a full acurracy report\n",
        "  if (analStats == 1):\n",
        "    print( classification_report(testlabel.to_frame(),prediction) )\n",
        "\n",
        "  # Calculate and Print the scores (Use true/false positive/negative to calculate the f1 score)\n",
        "  print(' Accuracy: %.2f%%' % (accuracy_score(testlabel, prediction)*100) )\n",
        "  print(' F1 Score: %.2f%%' % ( (tp/(tp+(fp+fn)/2))*100) )\n",
        "\n",
        "  # Finally, plot the comfusion matrix for a better visualization\n",
        "  plot_confusion_matrix(model, testdata, testlabel, display_labels=['Fake', 'Real', 'Fake', 'Real'])  \n",
        "  plt.show()  \n",
        "  print('\\n')\n",
        "\n",
        "#Run a test for each representation\n",
        "print(\" > Random Forest using BoW\")\n",
        "randomForestClassification(traindata_bow, trainlabel, testdata_bow, testlabel)\n",
        "print(\" > Random Forest using TF-IDF\")\n",
        "randomForestClassification(traindata_tfidf, trainlabel, testdata_tfidf, testlabel)\n",
        "print(\" > Random Forest using Word2Vec\")\n",
        "randomForestClassification(traindata_w2v, trainlabel, testdata_w2v, testlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LU70HPe38AJ"
      },
      "source": [
        "---\n",
        "# **Μέρος 3ο**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8oo1gW20BUp"
      },
      "source": [
        "Σε γενικές γραμμές, κατά την υλοποίηση των παραπάνω classifiers, προσπαθήσαμε να τους κάνουμε να λειτουργούν όσο το δυνατόν καλύτερα για τα δεδομένα όπως τους τα δίνουμε.<br/><br/>\n",
        "\n",
        "Για να βελτιώσουμε τα αποτελέσματα μας, προσπαθήσαμε να κάνουμε fine-tune τις παραμέτρους των classifiers, όπου αυτό ήταν δυνατό/αποτελεσματικό. Ακόμα, δοκιμάσαμε και εναλλακτικούς/υποκατάστατους classifiers (πχ LinearSVC )\n",
        "<br/><br/>\n",
        "\n",
        "Θεωρούμε ότι καταφέραμε αρκετά καλά αποτελέσματα across the board, με τους περισσότερους classifiers να επιτυγχάνουν ακρίβεια της τάξης 97%-99%. (Αναμενόμενο καθώς το dataset πανω στο οποίο δουλεύουμε είναι αρκετά εύκολο)\n",
        "<br/><br/>\n",
        "\n",
        "Χαμηλότερες ακρίβειες, έχουμε μόνο στον Naive Bayes και για τα τρια representations, και στο Random Forest μόνο για το word2Vec. (Τάξης 90%-95%)\n",
        "<br/><br/>\n",
        "\n",
        "Έχουμε ήδη αφιερώσει αρκετό χρόνο κάνοντας δοκιμές ωστε να βελτιώσουμε όλους τους classifiers του προηγούμενου ερωτήματος και έχουμε πετύχει αρκετά υψηλές ακρίβειες, οπότε δεν αναμένουμε να επιτύχουμε ιδιαίτερα μεγάλη βελτίωση στο ερώτημα αυτό.   \n",
        "\n",
        "Παρακάτω λοιπόν, θα προσπαθήσουμε να βελτιώσουμε την ακρίβεια του Naive Bayes Classifier, για bow και tfidf όσο το δυνατόν περισσότερο.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_nk3tEOnr43"
      },
      "source": [
        "Ένας τρόπος να βελτιώσουμε την ακρίβεια, είναι να \"καθαρίσουμε\" καλύτερα τα αρχικά μας δεδομένα, ή να σκεφτούμε νέα ευρετικά χαρακτηριστικά για τα δεδομένα μας και να τα προσθέσουμε στα χαρακτηριστικά που προκύπτουν από τις διάφορες αναπαραστάσεις.\n",
        "\n",
        "Έχουμε κάνει όλα τα βήματα προεπεξεργασίας και κανονικοποίησης δεδομένων που θεωρήσαμε πως μπορούν να βελτώσου τις επιδώσεις των μεθόδων μας, στο πρώτο κομμάτι της εργασίας. Έτσι στο σημείο αυτό πειραματιστήκαμε κυρίως με προσθήκη νέων χαρακτηριστικών απο εμας για βελτίωση της ακρίβειας.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPcjdKvW1g1Z"
      },
      "source": [
        "# Προσθήκη χαρακτηριστικών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUMbMGlv8KP"
      },
      "source": [
        "\n",
        "Με βάση τις παρατηρήσεις μας στο ερώτημα 2.β, μια ιδέα είναι να προσθέσουμε στήλες με τα πλήθη των χαρακτήρων στους τίτλους και στα κείμενα αντίστοιχα. Υπενθυμίζουμε οτι στο 2.β, παρατηρήσαμε πως τα ψεύτικα άρθρα τείνουν να έχουν μεγαλύτερους τίτλους και μικρότερο περιεχόμενο σχετικά με τα αληθινά.\n",
        "\n",
        "Φτιάξαμε μια στήλη με το πλήθος των συμβολων σε κάθε άρθρο, και άλλη μια με μια δική μας \"μετρική\", που προσπαθήσαμε με βάση την παραπάνω παρατήρηση να μεταφράσουμε πλήθος χαρακτήρων τίτλου και κειμένου, σε χαρακτηριστικό με κατανομή τέτοια ωστε να επιτρέπει classification. (True: μικρός τίτλος, μεγάλο περιεχόμενο, Fake: μεγάλος τίτλος, μικρό περιεχόμενο => χρησιμοποιούμε τις ιδιότητες αριθμητή/παρανωμαστή κλασμάτων και το κανονικοποιούμε διαιρώντας με το συνολικό πλήθος χαρακτήρων)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onq6YRNodUrY"
      },
      "source": [
        "# Adds the given 'characteristic-vector' to the existing ones (For both train and test sets)\n",
        "def addExtraHeur(traindata, testdata, newtraindata, newtestdata):\n",
        "  newtrn = np.array(newtraindata)\n",
        "  newtst = np.array(newtestdata)\n",
        "\n",
        "  new_traindata_bow = sparse.hstack( (traindata, newtrn[:, None]))\n",
        "  new_testdata_bow = sparse.hstack( (testdata, newtst[:, None]))\n",
        "\n",
        "  return (new_traindata_bow, new_testdata_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IxaVRCKdeiF"
      },
      "source": [
        "# We get the needed characteristics through train_test_split using the same parameters as above to ensure we have the correct order\n",
        "tit_traindata, tit_testdata, tit_trainlabel, tit_testlabel = train_test_split(format_df['titleLens'], format_df['Label'],train_size=0.8, random_state=250, stratify=format_df['Label'])\n",
        "met_traindata, met_testdata, met_trainlabel, met_testlabel = train_test_split(format_df['lenMetric'], format_df['Label'],train_size=0.8, random_state=250, stratify=format_df['Label'])\n",
        "\n",
        "# We add the heuristics to the representation we want\n",
        "new_traindata_bow, new_testdata_bow = addExtraHeur(traindata_bow, testdata_bow, tit_traindata, tit_testdata)\n",
        "new_traindata_bow, new_testdata_bow = addExtraHeur(new_traindata_bow, new_testdata_bow, met_traindata, met_testdata)\n",
        "\n",
        "# And calculate the new result\n",
        "naiveBayesClassification(new_traindata_bow, trainlabel, new_testdata_bow, testlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84C2pJEYyarV"
      },
      "source": [
        "Δυστυχώς βλέπουμε ότι τα επιπλέον χαρακτηριστικά μειώνουν κατα πολύ λιγο τις ακρίβειες μας. (Όσα χαρακτηριστικά και αν σκεφτήκαμε να δοκιμάσουμε)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Z7opLtyrNC"
      },
      "source": [
        "---\n",
        "Σημείωση: Προσπαθήσαμε να επιλέξουμε χαρακτηριστικά, των οποίων οι κατανομές να μπορούν να δώσουν χρήσιμη πληροφορία κατηγοριοποίησης, τυπώνοντας τις κατανομές τους"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFPHchhYliwd"
      },
      "source": [
        "# Return a dictionary with all the article 'classes', based on the amount of words in the given column\n",
        "def getNumDistribution(df, column):\n",
        "  pos = dict()\n",
        "  neg = dict()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    # num = round(row[column])\n",
        "    num = row[column]\n",
        "    if row['Label'] == '1':\n",
        "      if num not in pos:\n",
        "        pos[num] = 1\n",
        "      else:\n",
        "        pos[num] += 1\n",
        "    else:\n",
        "      if num not in neg:\n",
        "        neg[num] = 1\n",
        "      else:\n",
        "        neg[num] += 1\n",
        "\n",
        "  return (pos, neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y8tJ_c9zEs_"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "posdict, negdict = getNumDistribution(format_df, 'titleLens')\n",
        "\n",
        "keys, data = break_dict( posdict )\n",
        "plt.bar(keys, data)\n",
        "keys, data = break_dict( negdict )\n",
        "plt.bar(keys, data, alpha=0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnaSUOib0Tx6"
      },
      "source": [
        "(Βγαίνει περιεργο, αλλα χρησιμοποιησαμε plot αντι για bar σε κάποιες περιπτώσεις καθώς αντιμετοπίσαμε κάποια προβλήματα για πολύ μεγάλες κατανομές, και με την plot φαίνεται η πληροφορία που θέλουμε αξιοπρεπώς)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjeDahm5jOU6"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "posdict, negdict = getNumDistribution(format_df, 'lenMetric')\n",
        "\n",
        "keys, data = break_dict( posdict )\n",
        "plt.plot(keys, data)\n",
        "keys, data = break_dict( negdict )\n",
        "plt.plot(keys, data, alpha=0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sngQ5KHl1Goo"
      },
      "source": [
        "Βλέπουμε ότι υπάρχει διαχωρισμός, αλλα δυστυχώς δεν βλέπουμε καμία βελτίωση στα τελικά μας αποτελέσματα, ίσα ισα παρατηρούμε μια μικρή μείωση στις ακρίβειες μας."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYm4yZFIBpUO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byaIdDkJOgIv"
      },
      "source": [
        "Στην προσπάθεια μας να βρούμε επιπλέον χρήσιμα χαρακτηριστικά για να βελτιώσουμε τις επιδώσεις του classifier μας, \n",
        "δοκιμάσαμε να προσθέσουμε στα χαρακτηριστικά μας, και τις πληροφορίες 'Θέματος' και 'Ημερομηνίας' των άρθρων.\n",
        "Προς εκπληξη μας, η προσθήκη αυτή, μαζί με μια μικρή βελτίωση που προήλθε από το fine tuning των παραμέτρων του\n",
        "classifier, οδήγησαν τελικά σε μια βελτίωση της τάξης του 2% για τα bow και τα tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9nTiyEOBr2n"
      },
      "source": [
        "# Returns a list that contains all the words of each dataframe record in a srting\n",
        "def getRecStrList(df):\n",
        "  trainList = []\n",
        "  for index, row in df.iterrows():\n",
        "    txt = str(row['title']) + ' ' + str(row['text']) + ' ' + str(row['subject']) + ' ' + str(row['date'])\n",
        "    trainList.append(txt)\n",
        "  return trainList\n",
        "\n",
        "# Based on the true and fake dataframes, get a dataframe the data in a lot of different processed formats\n",
        "# to use for better testing down the line\n",
        "def getInitialFormat(true_df, fake_df):\n",
        "  # Create copies of the initial dataframes to not affect them\n",
        "  tmp_true = true_df.copy()\n",
        "  tmp_fake = fake_df.copy()\n",
        "  # tmp_true = true_df.head(2400).copy()\n",
        "  # tmp_fake = fake_df.head(2400).copy()\n",
        "\n",
        "  # Add the label column and merge the two dataframes\n",
        "  tmp_fake.insert(0,'label','0')\n",
        "  tmp_true.insert(0,'label','1')\n",
        "  tmp_df = pd.concat([tmp_true,tmp_fake], ignore_index=True)\n",
        "\n",
        "  # Create the new dataframe and add the processed level columns\n",
        "  format_df = pd.DataFrame()\n",
        "  format_df['Label'] = tmp_df['label']\n",
        "  format_df['RAW']   = getRecStrList(tmp_df)\n",
        "  format_df['Symbol'] = format_df['RAW'].str.lower().replace(r'\\s+', ' ', regex=True)\n",
        "  format_df['Preprocess'] = format_df['Symbol'].str.replace(r'[^a-zA-Z0-9]', ' ', regex=True)\n",
        "  format_df['StopWords'] = format_df['Preprocess'].apply( remove_stopwords )\n",
        "  format_df['Lemmatized'] = format_df['StopWords'].apply( lemmatize )\n",
        "\n",
        "  return format_df\n",
        "\n",
        "# (Mostly Used in the 2nd and 3rd part of the assignment for tests)\n",
        "format_df = getInitialFormat(true_df, fake_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYjh0ImFB-eK"
      },
      "source": [
        "# Create the train and test data/labels using the built in function train_test_split()\n",
        "traindata, testdata, trainlabel, testlabel = train_test_split(format_df['Lemmatized'], format_df['Label'],train_size=0.8, random_state=250, stratify=format_df['Label'])\n",
        "\n",
        "# Create all the different data representations that we will be working on:\n",
        "\n",
        "# BoW: Create a bow vectorizer, fit to it the train data and then transform the testing data \n",
        "# using the resulting bow, to end up with two BoWs that have the same amount of characteristics \n",
        "bow = CountVectorizer()\n",
        "traindata_bow = bow.fit_transform(traindata)\n",
        "testdata_bow = bow.transform(testdata)\n",
        "\n",
        "# TF-IDF: Create the tf-idf transformer using the generated BoWs from above\n",
        "tfidf = TfidfTransformer()\n",
        "traindata_tfidf = tfidf.fit_transform(traindata_bow)\n",
        "testdata_tfidf  = tfidf.transform(testdata_bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ru8ZXh3B-eL"
      },
      "source": [
        "# The word2vec vector size = the amount of 'features' of each word\n",
        "feature_amount = 256 \n",
        "\n",
        "# Returns an array containing the document vectors of each article from the given dataset\n",
        "def getDocVec(dataset, model):\n",
        "  # Get the document-feature vectors for each record-article of the train data\n",
        "  data_list = [] # Store all the data vectors in this list\n",
        "\n",
        "  # Get each article in the data\n",
        "  for i, row in dataset.to_frame().iterrows():\n",
        "    # Temporary array to store this row's vectors, initialized in zeros to act as an 'article-global' averaging vector\n",
        "    avg_vec = np.zeros(feature_amount)   \n",
        "    # Get the words of this article\n",
        "    tokens = nltk.word_tokenize(row['Lemmatized'])\n",
        "\n",
        "    # For every word in this article\n",
        "    for token in tokens:\n",
        "      # If it exists on our Word2vec dictionary\n",
        "      if token in model.wv:\n",
        "        # We add this word's vector to the article's total average vector, averaged by its word length\n",
        "        avg_vec += (model.wv[token]/len(tokens))\n",
        "\n",
        "    # Store the resulting document vector\n",
        "    data_list.append(avg_vec)\n",
        "\n",
        "  # Return the resulting list as an array\n",
        "  return np.array(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpxArVS4B-eL"
      },
      "source": [
        "# Word2Vec:\n",
        "\n",
        "# Break the train data into tokens to pass to word2vec \n",
        "# (We use only train data to train the model)\n",
        "tokens = [nltk.word_tokenize(strings) for strings in traindata.to_frame()['Lemmatized']]\n",
        "\n",
        "# Initialize and train the word2vec model\n",
        "# (We ended up with these parameter values after a bit of trial and error)\n",
        "w2v_model = Word2Vec(min_count=2, size=256, workers=multiprocessing.cpu_count(), window=5 , sg=0)\n",
        "w2v_model.build_vocab(tokens)\n",
        "w2v_model.train(tokens, total_examples=len(tokens), epochs=8)\n",
        "\n",
        "# Get the document vectors for each dataset\n",
        "traindata_w2v = getDocVec(traindata, w2v_model)\n",
        "testdata_w2v  = getDocVec(testdata, w2v_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6U5kEcoB-eM"
      },
      "source": [
        "# Add the min value of each vector array as an offset to the array to make it non-negative\n",
        "# And allow it to work with MultinomialNB() in Naive Bayes\n",
        "# It does not alter the data or change the accuracy, it just 'shifts' it to make it positive\n",
        "trainmin = np.amin(traindata_w2v)\n",
        "testmin = np.amin(testdata_w2v)\n",
        "\n",
        "if trainmin < 0 :\n",
        "  traindata_w2v += abs(trainmin)\n",
        "\n",
        "if testmin < 0 :\n",
        "  testdata_w2v += abs(testmin)\n",
        "\n",
        "# print(np.amin(traindata_w2v))\n",
        "# print(np.amin(testdata_w2v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG-fZZVNKVZF"
      },
      "source": [
        "Μετα από αρκετές δοκιμές, οι τιμές παραμέτρων alpha=0.0005 και fit_prior=False της MultinomialNB φαίνεται να μεγιστοποιούν την απόδοση της."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TatSfIUFCh8f"
      },
      "source": [
        "# Given the train and test data/labels, it calculates and prints the accuracy and f1 score of a Naive Bayes model \n",
        "def naiveBayesClassification(traindata, trainlabel, testdata, testlabel):\n",
        "  # Create a naive Bayes classification model\n",
        "  model = MultinomialNB( alpha=0.0005, fit_prior=False )\n",
        "\n",
        "  # Fit the train data to it\n",
        "  model.fit(traindata, trainlabel)\n",
        "\n",
        "  # Make a prediction\n",
        "  prediction = model.predict(testdata)\n",
        "  # Get the true/false positive/negative results using a confusion matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(testlabel, prediction).ravel()\n",
        "  # Get a full acurracy report\n",
        "  if (analStats == 1):\n",
        "    print( classification_report(testlabel.to_frame(),prediction) )\n",
        "\n",
        "  # Calculate and Print the scores (Use true/false positive/negative to calculate the f1 score)\n",
        "  print(' Accuracy: %.2f%%' % (accuracy_score(testlabel, prediction)*100) )\n",
        "  print(' F1 Score: %.2f%%' % ( (tp/(tp+(fp+fn)/2))*100) )\n",
        "\n",
        "  # Finally, plot the comfusion matrix for a better visualization\n",
        "  plot_confusion_matrix(model, testdata, testlabel, display_labels=['Fake', 'Real', 'Fake', 'Real'])  \n",
        "  plt.show()  \n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "print(\" > Naive Bayes using BoW\")\n",
        "naiveBayesClassification(traindata_bow, trainlabel, testdata_bow, testlabel)\n",
        "print(\" > Naive Bayes using TF-IDF\")\n",
        "naiveBayesClassification(traindata_tfidf, trainlabel, testdata_tfidf, testlabel)\n",
        "print(\" > Naive Bayes using Word2Vec\")\n",
        "naiveBayesClassification(traindata_w2v, trainlabel, testdata_w2v, testlabel)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}